data_path: "/glade/derecho/scratch/jsauer/SEALS_TRAINING/METEC7_SENSIT_8-15-24/"
#data_path: "/glade/derecho/scratch/cbecker/seals_sensit_large/"
#data_path: "/glade/derecho/scratch/jsauer/SEALS_TRAINING/Large_Training_Set_07-15-2024/"
out_path: "/glade/derecho/scratch/cbecker/SEALS_output/"
random_seed: 811
save_model: True
save_output: True
validation_ratio: 0.1
sensor_type_mask: -999
sensor_exist_mask: -1
scaler_type: "quantile"
#scaler_path: "/glade/derecho/scratch/jsauer/SEALS_TRAINING/TEST_TRANSFORMER/2024-08-03_1444/"
scaler_options:
  compression: 250
  distribution: "uniform"
data_options:
  remove_blind_samples: True
  use_noise: False
  noise_mean: 0.00000015
  noise_std: 0.0000001
restart_options:
  restart: False
  model_out_path: "/glade/derecho/scratch/cbecker/SEALS_output/2024-08-14_2222/"
predict_batch_size: 512
#models: ['block_rate_encoder']
#models: ['loc_rate_block_transformer']
models: ['block_transformer_leak_loc']

###### Location and Leak rate combined model
loc_rate_block_transformer:
  kwargs:
    encoder_layers: 5
    decoder_layers: 2
    hidden_size: 256 #512 #256
    n_heads: 72
    hidden_activation: "leaky_relu"
    output_activation: "sigmoid"
    dropout_rate: 0.1 #0.2
    n_outputs: 1
    block_size: 15 #60 #125 #30 #60 #10 #20
    n_coords: 3
    data_start_index: 4
  fit:
    epochs: 100
    verbose: 1
    batch_size: 32 #324 #256
  compile:
    loss: ["binary_crossentropy", "mean_absolute_error"]
    loss_weights: [4.0, 0.00001] #[20.0, 0.1]
  optimizer:
    learning_rate: 0.0001
    optimizer_type: "adam"
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    epsilon: 0.0000001
    sgd_momentum: 0
  loss_weight_change:
    shift_epoch: 35
    loss_weights: [1.0, 0.05]
  callbacks: ["loc_rate_metrics", "reduce_on_plateau", "model_checkpoint", "csv_logger"]
  callback_kwargs:
    reduce_on_plateau:
      monitor: "val_categorical_accuracy"
      mode: "max"
      min_lr: 0.000001
      factor: 0.3
      patience: 8
      verbose: 1

##### Location only model
block_transformer_leak_loc:
  kwargs:
    encoder_layers: 2
    decoder_layers: 2
    hidden_size: 1024
    n_heads: 32
    hidden_activation: "leaky_relu"
    output_activation: "sigmoid"
    n_outputs: 1
    block_size: 10
    n_coords: 3
    data_start_index: 4
  fit:
    epochs: 100
    verbose: 1
    batch_size: 32
  compile:
    loss: "binary_crossentropy"
    metrics: ["binary_accuracy"]
  optimizer:
    learning_rate: 0.0001
    optimizer_type: "adam"
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    epsilon: 0.0000001
    sgd_momentum: 0
  callbacks: ["loc_only_metrics", "reduce_on_plateau", "model_checkpoint", "csv_logger"]
  callback_kwargs:
    reduce_on_plateau:
      monitor: "val_categorical_accuracy"
      mode: "max"
      min_lr: 0.000001
      factor: 0.3
      patience: 8
      verbose: 1


######   Leak rate only model
block_rate_encoder:
  kwargs:
    encoder_layers: 5
    hidden_size: 256
    n_heads: 72
    hidden_activation: "leaky_relu"
    output_activation: "linear"
    n_outputs: 1
    block_size: 15
    n_coords: 3
    data_start_index: 4
  fit:
    epochs: 100
    verbose: 1
    batch_size: 32
  compile:
    loss: "mae"
    metrics: ["mse"]
  optimizer:
    learning_rate: 0.0001
    optimizer_type: "adam"
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    epsilon: 0.0000001
    sgd_momentum: 0
  callbacks: ["rate_only_metrics", "reduce_on_plateau", "model_checkpoint", "csv_logger"]
  callback_kwargs:
    reduce_on_plateau:
      monitor: "val_mae"
      mode: "min"
      min_lr: 0.000001
      factor: 0.3
      patience: 8
      verbose: 1

transformer_leak_loc:
  kwargs:
    encoder_layers: 2
    decoder_layers: 2
    hidden_size: 128
    n_heads: 8
    num_quantized_embeddings: 500
    hidden_activation: "relu"
    output_activation: "softmax"
    dropout_rate: 0.2
    use_quantizer: 0
    quantized_beta: 0.25
    n_outputs: 1
    min_filters: 4
    kernel_size: 3
    filter_growth_rate: 2
    n_conv_layers: 3
    pooling: "average"
    pool_size: 2
    padding: "valid"
  fit:
    epochs: 70
    verbose: 1
    batch_size: 1024
  compile:
    loss: "binary_crossentropy"
    metrics: ["binary_accuracy"]
  optimizer:
    learning_rate: 0.001
    optimizer_type: "adam"
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    epsilon: 0.0000001
    sgd_momentum: 0
transformer_leak_rate:
  kwargs:
    encoder_layers: 5
    hidden_size: 256
    n_heads: 72
    num_quantized_embeddings: 500
    hidden_activation: "relu"
    output_activation: "linear"
    dropout_rate: 0.2
    use_quantizer: False
    quantized_beta: 0.25
    n_outputs: 1
    min_filters: 4
    kernel_size: 3
    filter_growth_rate: 2
    n_conv_layers: 3
    pooling: "max"
    pool_size: 10
    padding: "valid"
  fit:
    epochs: 50
    verbose: 1
    batch_size: 512
  compile:
    loss: "mae"
    metrics: [ "mae" ]
  optimizer:
    learning_rate: 0.0001
    optimizer_type: "adam"
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    epsilon: 0.0000001
    sgd_momentum: 0
backtracker:
  kwargs:
    hidden_layers: 1
    hidden_neurons: 128
    activation: 'relu'
    n_output_tasks: 4
    optimizer: 'adam'
    lr: 0.001
    l2_weight: 0.00001
    batch_size: 128
    use_dropout: False
    dropout_alpha: 0.2
    epochs: 20
    verbose: 1
  preprocess:
    n_sensors: 3
    x_width: 40
    y_width: 40 
    factor_x: 0.4 
    factor_y: 0.4
  fit:
    kwargs: None
  compile:
    loss: "mse"
  optimizer:
    learning_rate: 0.001
    optimizer_type: "adam"
    adam_beta_1: 0.9
    adam_beta_2: 0.999
    epsilon: 0.0000001
    sgd_momentum: 0
gaussian_process:
  kwargs:
    num_met_sensors: 1
    normalize_y: True
    n_restarts_optimizer: 4
    length_scale_bounds: "fixed"
  fit:
    epochs: None


